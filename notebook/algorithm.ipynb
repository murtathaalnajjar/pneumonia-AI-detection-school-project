{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will use a machine learning framwork named pytorch\n",
    "## following this [tutorial](https://youtu.be/tHL5STNJKag?si=TgT5kABIFReWEcbD)\n",
    "## I dont actually understand what any of this stuff does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I later found out that you have to install pytorch like this for it to access your GPU\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# imports based on the tutorial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(torch.cuda.is_available()) # this checks weathers the GPU can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "  def __init__(self, data_dir, transform=None):\n",
    "    self.data = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx]\n",
    "\n",
    "  @property\n",
    "  def classes(self):\n",
    "    return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChestXrayDataset('ChestXRayDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5840"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 healthy   1 pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "image, label = dataset[1575]\n",
    "print(label)\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # no need to resize images\n",
    "    transforms.Resize((250, 250)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ChestXrayDataset('ChestXRayDataset', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete code under?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in dataloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2): # only 2 classes (healthy or pneumonia)\n",
    "        super(ChestXrayModel, self).__init__()\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        enet_out_size = 1280\n",
    "        self.classifier = nn.Linear(enet_out_size, num_classes)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChestXrayModel(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0268,  0.1410],\n",
       "        [ 0.3956, -0.1125],\n",
       "        [ 0.0680, -0.1564],\n",
       "        [ 0.1798, -0.2894],\n",
       "        [-0.1724,  0.1242],\n",
       "        [ 0.1471, -0.1342],\n",
       "        [ 0.0940, -0.1997],\n",
       "        [ 0.1817,  0.0101],\n",
       "        [-0.0708, -0.0891],\n",
       "        [-0.1379, -0.0258],\n",
       "        [ 0.1199,  0.0387],\n",
       "        [-0.0056,  0.1070],\n",
       "        [ 0.0790, -0.1018],\n",
       "        [-0.0350,  0.0233],\n",
       "        [ 0.0357, -0.2032],\n",
       "        [-0.0216, -0.0201]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the data into 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 0 files [00:00, ? files/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 5840 files [00:11, 519.87 files/s]\n"
     ]
    }
   ],
   "source": [
    "# import splitfolders\n",
    "\n",
    "# input_folder = \"ChestXrayDataset\"\n",
    "# output_folder = \"splitted_data\"\n",
    "\n",
    "# splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(0.7, 0.15, 0.15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating the training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((250, 250)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ChestXrayDataset('splitted_data/train', transform=transform)\n",
    "val_dataset   = ChestXrayDataset('splitted_data/val',   transform=transform)\n",
    "test_dataset  = ChestXrayDataset('splitted_data/test',  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I cant get it to use my GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5257c3afedd4a3292438f83ef21c689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f50600e9c7d49bcb59394232013bbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d8348d59e346d18cc7bb919359d279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54801c29b0e84b7d9f5d2f1d01ef9724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b90257c4af4a468720ba4f041c4fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "model = ChestXrayModel(num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "#\n",
    "#\n",
    "# training\n",
    "#\n",
    "#\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    train_loss = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "#\n",
    "#\n",
    "# validation\n",
    "#\n",
    "#\n",
    "    model.eval() # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc='Validation loop'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    val_loss = running_loss / len(val_loader.dataset)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Visualize losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
